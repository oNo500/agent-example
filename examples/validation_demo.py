"""
è§†é¢‘è¿½è¸ªéªŒè¯æ¼”ç¤º
å±•ç¤ºå®Œæ•´çš„éªŒè¯æµç¨‹å’Œå¯è§†åŒ–åŠŸèƒ½
"""

import os
import sys
import json
import asyncio

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.video_processor import VideoProcessor
from utils.tracking_validator import TrackingValidator
from utils.visualization_helper import VisualizationHelper
from core.agent import VideoAgent
from core.llm_client import FrameInfo, DetectionRegion
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def demo_frame_extraction_validation():
    """æ¼”ç¤ºå¸§æå–éªŒè¯"""
    print("ğŸ” 1. å¸§æå–éªŒè¯æ¼”ç¤º")
    print("=" * 50)
    
    video_path = "./assets/test1.mp4"
    if not os.path.exists(video_path):
        print("âŒ æµ‹è¯•è§†é¢‘ä¸å­˜åœ¨ï¼Œè¯·ç¡®ä¿ ./assets/test1.mp4 å­˜åœ¨")
        return
    
    # åˆå§‹åŒ–å¤„ç†å™¨å’ŒéªŒè¯å™¨
    processor = VideoProcessor()
    processor.enable_validation(True)
    
    # æå–å¸§ï¼ˆä¼šè‡ªåŠ¨è§¦å‘éªŒè¯ï¼‰
    print("ğŸ“¹ æ­£åœ¨æå–å…³é”®å¸§...")
    frames = processor.extract_frames(
        video_path=video_path,
        sample_rate=15,
        max_frames=24,
        use_motion_detection=True
    )
    
    print(f"âœ… æå–å®Œæˆï¼Œå…± {len(frames)} å¸§")
    
    # ç”Ÿæˆå¯è§†åŒ–
    if processor.visualizer:
        print("ğŸ“Š æ­£åœ¨ç”Ÿæˆå…³é”®å¸§åˆ†å¸ƒå›¾...")
        viz_path = processor.visualizer.visualize_keyframe_distribution(
            video_path, frames
        )
        if viz_path:
            print(f"ğŸ“ˆ å…³é”®å¸§åˆ†å¸ƒå›¾å·²ä¿å­˜: {viz_path}")
    
    return frames


async def demo_detection_validation():
    """æ¼”ç¤ºæ£€æµ‹ç»“æœéªŒè¯"""
    print("\nğŸ¯ 2. æ£€æµ‹ç»“æœéªŒè¯æ¼”ç¤º")
    print("=" * 50)
    
    # ä½¿ç”¨çœŸå®çš„è§†é¢‘å¸§æå–
    import cv2
    from utils.video_processor import VideoProcessor
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•è§†é¢‘æ–‡ä»¶
    test_video_path = "./assets/test1.mp4"  # ä½¿ç”¨ç°æœ‰çš„æµ‹è¯•è§†é¢‘
    if not os.path.exists(test_video_path):
        print(f"âŒ æµ‹è¯•è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {test_video_path}")
        print("ğŸ’¡ è¯·å°†æµ‹è¯•è§†é¢‘æ–‡ä»¶æ”¾åœ¨ assets/ ç›®å½•ä¸‹ï¼Œæˆ–ä¿®æ”¹ test_video_path å˜é‡")
        return []
    
    print(f"ğŸ“¹ æ­£åœ¨ä»çœŸå®è§†é¢‘æå–å…³é”®å¸§: {test_video_path}")
    processor = VideoProcessor()
    frames = processor.extract_frames(
        video_path=test_video_path,
        sample_rate=30,  # æ¯30å¸§æå–ä¸€å¸§
        max_frames=10    # æœ€å¤šæå–10å¸§ç”¨äºæ¼”ç¤º
    )
    
    print(f"âœ… æˆåŠŸæå– {len(frames)} ä¸ªå…³é”®å¸§")
    
    # ä½¿ç”¨çœŸå®çš„LLMæ£€æµ‹
    from core.agent import VideoAgent
    
    print("ğŸ¤– æ­£åœ¨è°ƒç”¨LLMè¿›è¡ŒçœŸå®æ£€æµ‹...")
    agent = VideoAgent()
    
    # è°ƒç”¨LLMåˆ†æè§†é¢‘å†…å®¹
    target_description = "æ‰‹æœº"  # æ£€æµ‹ç›®æ ‡
    llm_detections = await agent.analyze_video_content(test_video_path, target_description)
    
    print(f"âœ… LLMæ£€æµ‹å®Œæˆï¼Œå…±æ£€æµ‹åˆ° {len(llm_detections)} ä¸ªç›®æ ‡")
    
    # æ˜¾ç¤ºLLMæ£€æµ‹ç»“æœ
    for detection in llm_detections:
        print(f"   å¸§{detection.frame_id}: {detection.object_type} at ({detection.bbox[0]},{detection.bbox[1]},{detection.bbox[2]},{detection.bbox[3]}) - {detection.confidence:.2f}")
    
    sample_detections = llm_detections
    
    # è·å–çœŸå®è§†é¢‘ä¿¡æ¯
    cap = cv2.VideoCapture(test_video_path)
    video_info = {
        "width": int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),
        "height": int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),
        "fps": cap.get(cv2.CAP_PROP_FPS),
        "duration": int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) / cap.get(cv2.CAP_PROP_FPS)
    }
    cap.release()
    
    print(f"ğŸ“Š è§†é¢‘ä¿¡æ¯: {video_info['width']}x{video_info['height']}, {video_info['fps']:.1f}fps")
    
    # åˆå§‹åŒ–éªŒè¯å™¨
    validator = TrackingValidator()
    
    print("ğŸ¤– æ­£åœ¨éªŒè¯LLMæ£€æµ‹ç»“æœ...")
    validation_result = validator.validate_llm_detection(
        frames=frames,  # ä½¿ç”¨çœŸå®çš„å¸§ä¿¡æ¯
        detections=sample_detections,
        video_info=video_info
    )
    
    print(f"ğŸ“‹ éªŒè¯çŠ¶æ€: {validation_result.status}")
    print(f"ğŸ“ éªŒè¯ä¿¡æ¯: {validation_result.message}")
    
    # ç”Ÿæˆå¯è§†åŒ–ï¼ˆéœ€è¦å®é™…å¸§æ–‡ä»¶ï¼‰
    visualizer = VisualizationHelper()
    
    print("ğŸ“Š æ­£åœ¨ç”Ÿæˆè¿½è¸ªè½¨è¿¹å›¾...")
    trajectory_path = visualizer.visualize_tracking_trajectory(
        sample_detections, video_info
    )
    if trajectory_path:
        print(f"ğŸ“ˆ è¿½è¸ªè½¨è¿¹å›¾å·²ä¿å­˜: {trajectory_path}")
    
    return sample_detections


def demo_interpolation_validation():
    """æ¼”ç¤ºæ’å€¼éªŒè¯"""
    print("\nğŸ”„ 3. è¿½è¸ªæ’å€¼éªŒè¯æ¼”ç¤º")  
    print("=" * 50)
    
    # ä½¿ç”¨å‰é¢çš„æ£€æµ‹ç»“æœ
    sample_detections = [
        DetectionRegion(frame_id=15, object_type="æ‰‹æœº", bbox=(1000, 500, 200, 400), confidence=0.98, description="æ‰‹æœºè®¾å¤‡"),
        DetectionRegion(frame_id=45, object_type="æ‰‹æœº", bbox=(1200, 600, 220, 420), confidence=0.99, description="æ‰‹æœºè®¾å¤‡"),
        DetectionRegion(frame_id=75, object_type="æ‰‹æœº", bbox=(1100, 550, 210, 410), confidence=0.97, description="æ‰‹æœºè®¾å¤‡"),
    ]
    
    # åˆ›å»ºæ’å€¼å‡½æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰
    def simple_interpolation_func(frame_id, frame_regions_map, sorted_frame_ids):
        """ç®€åŒ–çš„æ’å€¼å‡½æ•°ç”¨äºæµ‹è¯•"""
        if frame_id in frame_regions_map:
            return frame_regions_map[frame_id]
        
        # æ‰¾æœ€è¿‘çš„å¸§
        closest_frame_id = min(sorted_frame_ids, key=lambda x: abs(x - frame_id))
        return frame_regions_map[closest_frame_id]
    
    # éªŒè¯æ’å€¼é€»è¾‘
    validator = TrackingValidator()
    test_frame_ids = [10, 20, 30, 40, 50, 60, 70, 80]  # æµ‹è¯•å¸§
    
    print("ğŸ”„ æ­£åœ¨éªŒè¯æ’å€¼é€»è¾‘...")
    validation_result = validator.validate_tracking_interpolation(
        regions=sample_detections,
        test_frame_ids=test_frame_ids,
        interpolation_func=simple_interpolation_func,
        total_video_frames=360
    )
    
    print(f"ğŸ“‹ éªŒè¯çŠ¶æ€: {validation_result.status}")
    print(f"ğŸ“ éªŒè¯ä¿¡æ¯: {validation_result.message}")
    
    if validation_result.details:
        stats = validation_result.details.get("interpolation_stats", {})
        print(f"ğŸ“Š æ’å€¼ç»Ÿè®¡: è¦†ç›–ç‡ {stats.get('coverage_rate', 'N/A')}")


def demo_coverage_visualization():
    """æ¼”ç¤ºè¦†ç›–ç‡å¯è§†åŒ–"""
    print("\nğŸ“ˆ 4. è¦†ç›–ç‡å¯è§†åŒ–æ¼”ç¤º")
    print("=" * 50)
    
    # æ¨¡æ‹Ÿæ•°æ®
    total_frames = 360
    detected_frames = [15, 45, 75, 105, 135, 165, 195, 225, 255, 285, 315, 345]
    interpolated_frames = list(range(1, 361))  # å‡è®¾æ‰€æœ‰å¸§éƒ½æœ‰æ’å€¼
    
    visualizer = VisualizationHelper()
    
    print("ğŸ“Š æ­£åœ¨ç”Ÿæˆè¦†ç›–ç‡ç»Ÿè®¡å›¾...")
    coverage_path = visualizer.visualize_coverage_statistics(
        total_frames=total_frames,
        detected_frames=detected_frames,
        interpolated_frames=interpolated_frames
    )
    
    if coverage_path:
        print(f"ğŸ“ˆ è¦†ç›–ç‡ç»Ÿè®¡å›¾å·²ä¿å­˜: {coverage_path}")
        coverage_rate = len(set(detected_frames + interpolated_frames)) / total_frames
        print(f"ğŸ“Š æ€»è¦†ç›–ç‡: {coverage_rate:.1%}")


def demo_validation_dashboard():
    """æ¼”ç¤ºéªŒè¯ä»ªè¡¨æ¿"""
    print("\nğŸ›ï¸ 5. éªŒè¯ä»ªè¡¨æ¿æ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºæ¨¡æ‹ŸéªŒè¯ç»“æœ
    from utils.tracking_validator import ValidationResult
    
    mock_results = [
        ValidationResult("frame_extraction", "pass", "å¸§æå–éªŒè¯é€šè¿‡"),
        ValidationResult("llm_detection", "pass", "LLMæ£€æµ‹éªŒè¯é€šè¿‡"), 
        ValidationResult("coordinate_conversion", "warning", "åæ ‡è½¬æ¢å­˜åœ¨è½»å¾®åå·®"),
        ValidationResult("tracking_interpolation", "fail", "æ’å€¼è¦†ç›–ç‡è¿‡ä½"),
        ValidationResult("mosaic_application", "pass", "æ‰“ç åº”ç”¨éªŒè¯é€šè¿‡"),
    ]
    
    visualizer = VisualizationHelper()
    
    print("ğŸ›ï¸ æ­£åœ¨ç”ŸæˆéªŒè¯ä»ªè¡¨æ¿...")
    dashboard_path = visualizer.create_validation_dashboard(mock_results)
    
    if dashboard_path:
        print(f"ğŸ“Š éªŒè¯ä»ªè¡¨æ¿å·²ä¿å­˜: {dashboard_path}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        total = len(mock_results)
        passed = sum(1 for r in mock_results if r.status == "pass")
        failed = sum(1 for r in mock_results if r.status == "fail")
        warnings = sum(1 for r in mock_results if r.status == "warning")
        
        print(f"ğŸ“ˆ éªŒè¯æ‘˜è¦: {passed}/{total} é€šè¿‡, {failed} å¤±è´¥, {warnings} è­¦å‘Š")


async def demo_end_to_end_validation():
    """æ¼”ç¤ºç«¯åˆ°ç«¯éªŒè¯ï¼ˆéœ€è¦çœŸå®è§†é¢‘å¤„ç†ï¼‰"""
    print("\nğŸ¯ 6. ç«¯åˆ°ç«¯éªŒè¯æ¼”ç¤º")
    print("=" * 50)
    
    video_path = "./assets/test1.mp4"
    if not os.path.exists(video_path):
        print("âŒ æµ‹è¯•è§†é¢‘ä¸å­˜åœ¨ï¼Œè·³è¿‡ç«¯åˆ°ç«¯éªŒè¯")
        return
    
    try:
        # åˆå§‹åŒ–ä»£ç†ï¼ˆå¯ç”¨éªŒè¯æ¨¡å¼ï¼‰
        agent = VideoAgent()
        
        print("ğŸ¬ æ­£åœ¨æ‰§è¡Œå®Œæ•´çš„è§†é¢‘å¤„ç†æµç¨‹...")
        print("   è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´...")
        
        # æ‰§è¡Œå®Œæ•´çš„è¿½è¸ªæ‰“ç æµç¨‹
        result = await agent.process_request(
            "ä¸ºè§†é¢‘ä¸­çš„æ‰‹æœºè¿›è¡Œæ™ºèƒ½è¿½è¸ªæ‰“ç å¤„ç†",
            video_path
        )
        
        print("âœ… ç«¯åˆ°ç«¯å¤„ç†å®Œæˆ")
        print("ğŸ“‹ å¤„ç†ç»“æœ:")
        print(result[:200] + "..." if len(result) > 200 else result)
        
    except Exception as e:
        print(f"âŒ ç«¯åˆ°ç«¯éªŒè¯å¤±è´¥: {str(e)}")


async def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸ” è§†é¢‘è¿½è¸ªéªŒè¯ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 60)
    print("æœ¬æ¼”ç¤ºå°†å±•ç¤ºå®Œæ•´çš„éªŒè¯æµç¨‹ï¼ŒåŒ…æ‹¬ï¼š")
    print("â€¢ å¸§æå–éªŒè¯")
    print("â€¢ æ£€æµ‹ç»“æœéªŒè¯") 
    print("â€¢ è¿½è¸ªæ’å€¼éªŒè¯")
    print("â€¢ è¦†ç›–ç‡å¯è§†åŒ–")
    print("â€¢ éªŒè¯ä»ªè¡¨æ¿")
    print("â€¢ ç«¯åˆ°ç«¯éªŒè¯")
    print()
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dirs = ["./output", "./output/validation", "./output/visualization"]
    for dir_path in output_dirs:
        os.makedirs(dir_path, exist_ok=True)
    
    try:
        # æ‰§è¡Œå„ä¸ªæ¼”ç¤º
        demo_frame_extraction_validation()
        await demo_detection_validation()
        demo_interpolation_validation()
        demo_coverage_visualization()
        demo_validation_dashboard()
        
        # ç«¯åˆ°ç«¯éªŒè¯ï¼ˆå¯é€‰ï¼Œéœ€è¦æ—¶é—´ï¼‰
        print("\nâ“ æ˜¯å¦æ‰§è¡Œç«¯åˆ°ç«¯éªŒè¯ï¼Ÿï¼ˆéœ€è¦è¾ƒé•¿æ—¶é—´ï¼‰")
        choice = input("è¾“å…¥ 'y' æ‰§è¡Œï¼Œå…¶ä»–é”®è·³è¿‡: ").strip().lower()
        if choice == 'y':
            asyncio.run(demo_end_to_end_validation())
        else:
            print("â­ï¸ è·³è¿‡ç«¯åˆ°ç«¯éªŒè¯")
        
        print("\nğŸ‰ æ‰€æœ‰éªŒè¯æ¼”ç¤ºå®Œæˆï¼")
        print("ğŸ“ éªŒè¯ç»“æœå’Œå¯è§†åŒ–å›¾ç‰‡å·²ä¿å­˜åœ¨ ./output/ ç›®å½•ä¸­")
        print("ğŸ“Š è¯·æŸ¥çœ‹ç”Ÿæˆçš„å›¾ç‰‡å’ŒJSONæŠ¥å‘Šä»¥äº†è§£éªŒè¯ç»“æœ")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ¼”ç¤º")
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())