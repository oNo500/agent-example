"""
è§†é¢‘è¿½è¸ªéªŒè¯å·¥å…·
æä¾›å®Œæ•´çš„éªŒè¯æµç¨‹ï¼Œç¡®ä¿æ‰“ç è¿½è¸ªç³»ç»Ÿçš„å‡†ç¡®æ€§å’Œå¯é æ€§
"""

import os
import json
import cv2
import numpy as np
from typing import List, Dict, Tuple, Optional, Any
from dataclasses import dataclass
from datetime import datetime

from core.llm_client import FrameInfo, DetectionRegion
from core.exceptions import VideoProcessingError
from utils.html_visualizer import HTMLVisualizer


@dataclass
class ValidationResult:
    """éªŒè¯ç»“æœæ•°æ®ç»“æ„"""
    stage: str
    status: str  # "pass", "fail", "warning"
    message: str
    details: Dict[str, Any] = None
    timestamp: str = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now().isoformat()


class TrackingValidator:
    """è§†é¢‘è¿½è¸ªç³»ç»ŸéªŒè¯å™¨"""
    
    def __init__(self, output_dir: str = "./output/validation"):
        """åˆå§‹åŒ–éªŒè¯å™¨
        
        Args:
            output_dir: éªŒè¯ç»“æœè¾“å‡ºç›®å½•
        """
        self.output_dir = output_dir
        self.validation_results: List[ValidationResult] = []
        os.makedirs(output_dir, exist_ok=True)
        
        # åˆå§‹åŒ–HTMLå¯è§†åŒ–å™¨
        self.html_visualizer = HTMLVisualizer()
        
    def validate_frame_extraction(
        self, 
        video_path: str, 
        extracted_frames: List[FrameInfo],
        expected_count: int = None
    ) -> ValidationResult:
        """éªŒè¯å¸§æå–ç»“æœ
        
        Args:
            video_path: è§†é¢‘è·¯å¾„
            extracted_frames: æå–çš„å¸§ä¿¡æ¯åˆ—è¡¨
            expected_count: é¢„æœŸå¸§æ•°
            
        Returns:
            éªŒè¯ç»“æœ
        """
        try:
            # è·å–è§†é¢‘åŸºæœ¬ä¿¡æ¯
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                return ValidationResult(
                    stage="frame_extraction",
                    status="fail", 
                    message=f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}"
                )
            
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            duration = total_frames / fps if fps > 0 else 0
            cap.release()
            
            # éªŒè¯æå–ç»“æœ
            issues = []
            
            # æ£€æŸ¥1: å¸§æ•°é‡
            if expected_count and len(extracted_frames) != expected_count:
                issues.append(f"å¸§æ•°é‡ä¸åŒ¹é…: æœŸæœ›{expected_count}, å®é™…{len(extracted_frames)}")
            
            # æ£€æŸ¥2: å¸§IDèŒƒå›´
            frame_ids = [frame.frame_id for frame in extracted_frames]
            min_id, max_id = min(frame_ids), max(frame_ids)
            if min_id < 1 or max_id > total_frames:
                issues.append(f"å¸§IDè¶…å‡ºèŒƒå›´: {min_id}-{max_id}, è§†é¢‘æ€»å¸§æ•°{total_frames}")
            
            # æ£€æŸ¥3: æ—¶é—´æˆ³åˆç†æ€§
            timestamps = [frame.timestamp for frame in extracted_frames]
            if any(t < 0 or t > duration for t in timestamps):
                issues.append(f"æ—¶é—´æˆ³è¶…å‡ºèŒƒå›´: 0-{duration}s")
            
            # æ£€æŸ¥4: æ–‡ä»¶å­˜åœ¨æ€§
            missing_files = []
            for frame in extracted_frames:
                if not os.path.exists(frame.image_path):
                    missing_files.append(frame.image_path)
            if missing_files:
                issues.append(f"ç¼ºå¤±å¸§æ–‡ä»¶: {len(missing_files)}ä¸ª")
            
            # æ£€æŸ¥5: å¸§åˆ†å¸ƒå‡åŒ€æ€§
            if len(frame_ids) > 1:
                intervals = [frame_ids[i+1] - frame_ids[i] for i in range(len(frame_ids)-1)]
                avg_interval = sum(intervals) / len(intervals)
                max_deviation = max(abs(interval - avg_interval) for interval in intervals)
                if max_deviation > avg_interval * 0.5:  # å…è®¸50%çš„åå·®
                    issues.append(f"å¸§åˆ†å¸ƒä¸å‡åŒ€: å¹³å‡é—´éš”{avg_interval:.1f}, æœ€å¤§åå·®{max_deviation:.1f}")
            
            status = "fail" if issues else "pass"
            message = "; ".join(issues) if issues else "å¸§æå–éªŒè¯é€šè¿‡"
            
            details = {
                "video_info": {
                    "total_frames": total_frames,
                    "fps": fps,
                    "duration": duration
                },
                "extraction_info": {
                    "extracted_count": len(extracted_frames),
                    "frame_id_range": f"{min_id}-{max_id}",
                    "timestamp_range": f"{min(timestamps):.2f}-{max(timestamps):.2f}s"
                },
                "issues": issues
            }
            
            result = ValidationResult(
                stage="frame_extraction",
                status=status,
                message=message,
                details=details
            )
            
            self.validation_results.append(result)
            return result
            
        except Exception as e:
            result = ValidationResult(
                stage="frame_extraction",
                status="fail",
                message=f"éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}"
            )
            self.validation_results.append(result)
            return result
    
    def validate_llm_detection(
        self,
        frames: List[FrameInfo],
        detections: List[DetectionRegion],
        video_info: Dict = None
    ) -> ValidationResult:
        """éªŒè¯LLMæ£€æµ‹ç»“æœ
        
        Args:
            frames: å¸§ä¿¡æ¯åˆ—è¡¨
            detections: æ£€æµ‹ç»“æœåˆ—è¡¨
            video_info: è§†é¢‘ä¿¡æ¯
            
        Returns:
            éªŒè¯ç»“æœ
        """
        try:
            issues = []
            
            # æ£€æŸ¥1: æ£€æµ‹æ•°é‡åˆç†æ€§
            frame_count = len(frames)
            detection_count = len(detections)
            
            if detection_count == 0:
                issues.append("æ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡")
            elif detection_count > frame_count * 3:  # å…è®¸æ¯å¸§æœ€å¤š3ä¸ªç›®æ ‡
                issues.append(f"æ£€æµ‹ç›®æ ‡è¿‡å¤š: {detection_count} ä¸ªç›®æ ‡åœ¨ {frame_count} å¸§ä¸­")
            
            # æ£€æŸ¥2: å¸§è¦†ç›–ç‡
            detected_frames = set(det.frame_id for det in detections)
            frame_ids = set(frame.frame_id for frame in frames)
            coverage_rate = len(detected_frames) / len(frame_ids) if frame_ids else 0
            
            if coverage_rate < 0.5:  # è‡³å°‘50%çš„å¸§åº”è¯¥æœ‰æ£€æµ‹ç»“æœ
                issues.append(f"å¸§è¦†ç›–ç‡è¿‡ä½: {coverage_rate:.1%}")
            
            # æ£€æŸ¥3: åæ ‡èŒƒå›´éªŒè¯
            if video_info:
                video_width = video_info.get('width', 1920)
                video_height = video_info.get('height', 1080)
                
                coord_issues = []
                for det in detections:
                    x, y, w, h = det.bbox
                    if x < 0 or y < 0 or x + w > video_width or y + h > video_height:
                        coord_issues.append(f"å¸§{det.frame_id}: ({x},{y},{w},{h})")
                
                if coord_issues:
                    issues.append(f"åæ ‡è¶…å‡ºè§†é¢‘èŒƒå›´ ({video_width}x{video_height}): {len(coord_issues)}ä¸ª")
            
            # æ£€æŸ¥4: ç½®ä¿¡åº¦åˆ†å¸ƒ
            confidences = [det.confidence for det in detections]
            if confidences:
                avg_confidence = sum(confidences) / len(confidences)
                low_confidence_count = sum(1 for c in confidences if c < 0.5)
                
                if avg_confidence < 0.7:
                    issues.append(f"å¹³å‡ç½®ä¿¡åº¦è¿‡ä½: {avg_confidence:.2f}")
                if low_confidence_count > len(confidences) * 0.3:
                    issues.append(f"ä½ç½®ä¿¡åº¦æ£€æµ‹è¿‡å¤š: {low_confidence_count}/{len(confidences)}")
            
            # æ£€æŸ¥5: åŒºåŸŸå¤§å°åˆç†æ€§
            if video_info:
                video_area = video_info.get('width', 1920) * video_info.get('height', 1080)
                large_regions = 0
                tiny_regions = 0
                
                for det in detections:
                    w, h = det.bbox[2], det.bbox[3]
                    area = w * h
                    area_ratio = area / video_area
                    
                    if area_ratio > 0.25:  # è¶…è¿‡è§†é¢‘é¢ç§¯25%
                        large_regions += 1
                    elif area_ratio < 0.001:  # å°äºè§†é¢‘é¢ç§¯0.1%
                        tiny_regions += 1
                
                if large_regions > 0:
                    issues.append(f"æ£€æµ‹åŒºåŸŸè¿‡å¤§: {large_regions}ä¸ª")
                if tiny_regions > len(detections) * 0.2:
                    issues.append(f"æ£€æµ‹åŒºåŸŸè¿‡å°: {tiny_regions}ä¸ª")
            
            status = "fail" if issues else "pass"
            message = "; ".join(issues) if issues else "LLMæ£€æµ‹éªŒè¯é€šè¿‡"
            
            details = {
                "detection_stats": {
                    "total_detections": detection_count,
                    "frames_with_detection": len(detected_frames),
                    "coverage_rate": f"{coverage_rate:.1%}",
                    "avg_confidence": f"{sum(confidences)/len(confidences):.2f}" if confidences else "N/A"
                },
                "frame_distribution": dict(zip(*np.unique([det.frame_id for det in detections], return_counts=True))),
                "issues": issues
            }
            
            result = ValidationResult(
                stage="llm_detection",
                status=status,
                message=message,
                details=details
            )
            
            # ç”ŸæˆHTMLå¯è§†åŒ–é¡µé¢
            try:
                print("ğŸŒ æ­£åœ¨ç”ŸæˆHTMLå¯è§†åŒ–é¡µé¢...")
                html_path = self.html_visualizer.create_detection_visualization(
                    frames=frames,
                    detections=detections,
                    title=f"LLMæ£€æµ‹ç»“æœéªŒè¯ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                )
                
                # å°†HTMLè·¯å¾„æ·»åŠ åˆ°ç»“æœè¯¦æƒ…ä¸­
                details["html_visualization"] = html_path
                result.details = details
                
                print(f"ğŸ“Š HTMLå¯è§†åŒ–é¡µé¢å·²ç”Ÿæˆï¼Œå¯åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€æŸ¥çœ‹: {html_path}")
                
            except Exception as e:
                print(f"âš ï¸ HTMLå¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
            
            self.validation_results.append(result)
            return result
            
        except Exception as e:
            result = ValidationResult(
                stage="llm_detection",
                status="fail",
                message=f"éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}"
            )
            self.validation_results.append(result)
            return result
    
    def validate_coordinate_conversion(
        self,
        detections: List[DetectionRegion],
        video_info: Dict,
        frame_info: List[FrameInfo]
    ) -> ValidationResult:
        """éªŒè¯åæ ‡è½¬æ¢çš„ä¸€è‡´æ€§
        
        Args:
            detections: æ£€æµ‹ç»“æœï¼ˆè§†é¢‘åæ ‡ç³»ï¼‰
            video_info: è§†é¢‘ä¿¡æ¯
            frame_info: å¸§ä¿¡æ¯ï¼ˆç”¨äºè·å–åŸå§‹å›¾ç‰‡å°ºå¯¸ï¼‰
            
        Returns:
            éªŒè¯ç»“æœ
        """
        try:
            issues = []
            
            video_width = video_info.get('width', 1920)
            video_height = video_info.get('height', 1080)
            
            # æ£€æŸ¥æ ·æœ¬å¸§çš„åæ ‡ä¸€è‡´æ€§
            sample_frame = frame_info[0] if frame_info else None
            if sample_frame and os.path.exists(sample_frame.image_path):
                # è¯»å–æå–å¸§çš„å®é™…å°ºå¯¸
                img = cv2.imread(sample_frame.image_path)
                if img is not None:
                    img_height, img_width = img.shape[:2]
                    
                    # è®¡ç®—ç¼©æ”¾å› å­
                    scale_x = video_width / img_width
                    scale_y = video_height / img_height
                    
                    # æ£€æŸ¥ç¼©æ”¾å› å­çš„åˆç†æ€§
                    if abs(scale_x - scale_y) > 0.1:  # å®½é«˜æ¯”åº”è¯¥åŸºæœ¬ä¸€è‡´
                        issues.append(f"ç¼©æ”¾å› å­ä¸ä¸€è‡´: X={scale_x:.2f}, Y={scale_y:.2f}")
                    
                    # éªŒè¯åæ ‡è½¬æ¢ç»“æœ
                    coord_errors = []
                    for det in detections[:5]:  # æ£€æŸ¥å‰5ä¸ªæ£€æµ‹ç»“æœ
                        x, y, w, h = det.bbox
                        
                        # åå‘è½¬æ¢åˆ°å›¾ç‰‡åæ ‡ç³»
                        img_x = x / scale_x
                        img_y = y / scale_y
                        img_w = w / scale_x  
                        img_h = h / scale_y
                        
                        # æ£€æŸ¥æ˜¯å¦åœ¨å›¾ç‰‡èŒƒå›´å†…
                        if (img_x < 0 or img_y < 0 or 
                            img_x + img_w > img_width or 
                            img_y + img_h > img_height):
                            coord_errors.append(f"å¸§{det.frame_id}")
                    
                    if coord_errors:
                        issues.append(f"åæ ‡è½¬æ¢é”™è¯¯: {len(coord_errors)}ä¸ªæ£€æµ‹ç»“æœ")
                    
                    details = {
                        "video_resolution": f"{video_width}x{video_height}",
                        "frame_resolution": f"{img_width}x{img_height}",
                        "scale_factors": f"X={scale_x:.2f}, Y={scale_y:.2f}",
                        "sample_conversions": [
                            {
                                "frame_id": det.frame_id,
                                "video_coords": det.bbox,
                                "image_coords": [
                                    int(det.bbox[0]/scale_x), 
                                    int(det.bbox[1]/scale_y),
                                    int(det.bbox[2]/scale_x), 
                                    int(det.bbox[3]/scale_y)
                                ]
                            } for det in detections[:3]
                        ]
                    }
            else:
                issues.append("æ— æ³•è¯»å–æ ·æœ¬å¸§è¿›è¡Œåæ ‡éªŒè¯")
                details = {}
            
            status = "fail" if issues else "pass"
            message = "; ".join(issues) if issues else "åæ ‡è½¬æ¢éªŒè¯é€šè¿‡"
            
            result = ValidationResult(
                stage="coordinate_conversion", 
                status=status,
                message=message,
                details=details
            )
            
            self.validation_results.append(result)
            return result
            
        except Exception as e:
            result = ValidationResult(
                stage="coordinate_conversion",
                status="fail", 
                message=f"éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}"
            )
            self.validation_results.append(result)
            return result
    
    def generate_validation_report(self, output_file: str = None) -> str:
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤åœ¨output_dirä¸­
            
        Returns:
            æŠ¥å‘Šå†…å®¹å­—ç¬¦ä¸²
        """
        if not output_file:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = os.path.join(self.output_dir, f"validation_report_{timestamp}.json")
        
        # ç»Ÿè®¡ç»“æœ
        total_tests = len(self.validation_results)
        passed_tests = sum(1 for r in self.validation_results if r.status == "pass")
        failed_tests = sum(1 for r in self.validation_results if r.status == "fail") 
        warning_tests = sum(1 for r in self.validation_results if r.status == "warning")
        
        report = {
            "summary": {
                "total_tests": total_tests,
                "passed": passed_tests,
                "failed": failed_tests,
                "warnings": warning_tests,
                "success_rate": f"{passed_tests/total_tests:.1%}" if total_tests > 0 else "0%",
                "generated_at": datetime.now().isoformat()
            },
            "results": [
                {
                    "stage": r.stage,
                    "status": r.status, 
                    "message": r.message,
                    "details": r.details,
                    "timestamp": r.timestamp
                } for r in self.validation_results
            ],
            "recommendations": self._generate_recommendations()
        }
        
        # ä¿å­˜æŠ¥å‘Š
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # ç”Ÿæˆæ–‡æœ¬æ‘˜è¦
        summary = f"""
ğŸ” è§†é¢‘è¿½è¸ªéªŒè¯æŠ¥å‘Š
==================
æµ‹è¯•æ€»æ•°: {total_tests}
âœ… é€šè¿‡: {passed_tests} 
âŒ å¤±è´¥: {failed_tests}
âš ï¸  è­¦å‘Š: {warning_tests}
æˆåŠŸç‡: {passed_tests/total_tests:.1%}

è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {output_file}
        """.strip()
        
        return summary
    
    def validate_tracking_interpolation(
        self,
        regions: List[DetectionRegion], 
        test_frame_ids: List[int],
        interpolation_func,
        total_video_frames: int
    ) -> ValidationResult:
        """éªŒè¯è¿½è¸ªæ’å€¼é€»è¾‘
        
        Args:
            regions: å…³é”®å¸§æ£€æµ‹åŒºåŸŸ
            test_frame_ids: æµ‹è¯•å¸§IDåˆ—è¡¨
            interpolation_func: æ’å€¼å‡½æ•°
            total_video_frames: è§†é¢‘æ€»å¸§æ•°
            
        Returns:
            éªŒè¯ç»“æœ
        """
        try:
            issues = []
            
            # æŒ‰å¸§IDåˆ†ç»„åŒºåŸŸ
            frame_regions_map = {}
            for region in regions:
                if region.frame_id not in frame_regions_map:
                    frame_regions_map[region.frame_id] = []
                frame_regions_map[region.frame_id].append(region)
            
            sorted_frame_ids = sorted(frame_regions_map.keys())
            
            # æ£€æŸ¥1: å…³é”®å¸§åˆ†å¸ƒ
            if len(sorted_frame_ids) < 2:
                issues.append("å…³é”®å¸§æ•°é‡è¿‡å°‘ï¼Œæ— æ³•è¿›è¡Œæœ‰æ•ˆæ’å€¼")
            else:
                # è®¡ç®—å…³é”®å¸§é—´éš”
                intervals = [sorted_frame_ids[i+1] - sorted_frame_ids[i] 
                           for i in range(len(sorted_frame_ids)-1)]
                max_interval = max(intervals)
                avg_interval = sum(intervals) / len(intervals)
                
                if max_interval > total_video_frames * 0.3:  # æœ€å¤§é—´éš”ä¸åº”è¶…è¿‡30%è§†é¢‘é•¿åº¦
                    issues.append(f"å…³é”®å¸§é—´éš”è¿‡å¤§: æœ€å¤§{max_interval}å¸§")
            
            # æ£€æŸ¥2: æ’å€¼ç»“æœéªŒè¯
            interpolation_results = []
            coverage_gaps = []
            
            for test_frame_id in test_frame_ids:
                try:
                    result = interpolation_func(test_frame_id, frame_regions_map, sorted_frame_ids)
                    interpolation_results.append({
                        "frame_id": test_frame_id,
                        "result_count": len(result),
                        "has_result": len(result) > 0
                    })
                    
                    if len(result) == 0:
                        coverage_gaps.append(test_frame_id)
                        
                except Exception as e:
                    issues.append(f"æ’å€¼å‡½æ•°åœ¨å¸§{test_frame_id}å‡ºé”™: {str(e)}")
            
            # æ£€æŸ¥3: è¦†ç›–ç‡
            coverage_rate = sum(1 for r in interpolation_results if r["has_result"]) / len(interpolation_results)
            if coverage_rate < 0.9:  # è‡³å°‘90%çš„å¸§åº”è¯¥æœ‰æ’å€¼ç»“æœ
                issues.append(f"æ’å€¼è¦†ç›–ç‡è¿‡ä½: {coverage_rate:.1%}")
            
            # æ£€æŸ¥4: è¿ç»­æ€§
            if len(coverage_gaps) > 0:
                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨è¿ç»­çš„è¦†ç›–ç©ºç™½
                gap_groups = []
                current_group = [coverage_gaps[0]]
                
                for i in range(1, len(coverage_gaps)):
                    if coverage_gaps[i] - coverage_gaps[i-1] == 1:
                        current_group.append(coverage_gaps[i])
                    else:
                        gap_groups.append(current_group)
                        current_group = [coverage_gaps[i]]
                gap_groups.append(current_group)
                
                large_gaps = [g for g in gap_groups if len(g) > 5]  # è¶…è¿‡5å¸§çš„è¿ç»­ç©ºç™½
                if large_gaps:
                    issues.append(f"å­˜åœ¨å¤§çš„è¦†ç›–ç©ºç™½: {len(large_gaps)}å¤„")
            
            status = "fail" if issues else "pass"
            message = "; ".join(issues) if issues else "è¿½è¸ªæ’å€¼éªŒè¯é€šè¿‡"
            
            details = {
                "keyframe_stats": {
                    "total_keyframes": len(sorted_frame_ids),
                    "keyframe_range": f"{min(sorted_frame_ids)}-{max(sorted_frame_ids)}",
                    "avg_interval": f"{sum(intervals)/len(intervals):.1f}" if intervals else "N/A"
                },
                "interpolation_stats": {
                    "test_frames": len(test_frame_ids),
                    "coverage_rate": f"{coverage_rate:.1%}", 
                    "coverage_gaps": len(coverage_gaps)
                },
                "sample_results": interpolation_results[:10],  # å‰10ä¸ªç»“æœä½œä¸ºæ ·æœ¬
                "issues": issues
            }
            
            result = ValidationResult(
                stage="tracking_interpolation",
                status=status,
                message=message,
                details=details
            )
            
            self.validation_results.append(result)
            return result
            
        except Exception as e:
            result = ValidationResult(
                stage="tracking_interpolation",
                status="fail",
                message=f"éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}"
            )
            self.validation_results.append(result)
            return result
    
    def validate_mosaic_application(
        self,
        sample_frame_path: str,
        regions: List[DetectionRegion],
        mosaic_func,
        mosaic_strength: int = 15
    ) -> ValidationResult:
        """éªŒè¯æ‰“ç åº”ç”¨æ•ˆæœ
        
        Args:
            sample_frame_path: æ ·æœ¬å¸§æ–‡ä»¶è·¯å¾„
            regions: éœ€è¦æ‰“ç çš„åŒºåŸŸ
            mosaic_func: æ‰“ç å‡½æ•°
            mosaic_strength: æ‰“ç å¼ºåº¦
            
        Returns:
            éªŒè¯ç»“æœ
        """
        try:
            issues = []
            
            # æ£€æŸ¥1: æ ·æœ¬å¸§å­˜åœ¨æ€§å’Œå¯è¯»æ€§
            if not os.path.exists(sample_frame_path):
                return ValidationResult(
                    stage="mosaic_application",
                    status="fail",
                    message=f"æ ·æœ¬å¸§ä¸å­˜åœ¨: {sample_frame_path}"
                )
            
            original_frame = cv2.imread(sample_frame_path)
            if original_frame is None:
                return ValidationResult(
                    stage="mosaic_application",
                    status="fail", 
                    message=f"æ— æ³•è¯»å–æ ·æœ¬å¸§: {sample_frame_path}"
                )
            
            frame_height, frame_width = original_frame.shape[:2]
            
            # æ£€æŸ¥2: åŒºåŸŸåæ ‡æœ‰æ•ˆæ€§
            valid_regions = []
            invalid_regions = []
            
            for region in regions:
                x, y, w, h = region.bbox
                if (x >= 0 and y >= 0 and 
                    x + w <= frame_width and 
                    y + h <= frame_height and
                    w > 0 and h > 0):
                    valid_regions.append(region)
                else:
                    invalid_regions.append(region)
            
            if invalid_regions:
                issues.append(f"æ— æ•ˆåŒºåŸŸåæ ‡: {len(invalid_regions)}ä¸ª")
            
            if not valid_regions:
                return ValidationResult(
                    stage="mosaic_application",
                    status="fail",
                    message="æ²¡æœ‰æœ‰æ•ˆçš„æ‰“ç åŒºåŸŸ"
                )
            
            # æ£€æŸ¥3: åº”ç”¨æ‰“ç æ•ˆæœ
            try:
                processed_frame = original_frame.copy()
                for region in valid_regions:
                    processed_frame = mosaic_func(processed_frame, region.bbox, mosaic_strength)
                
                # éªŒè¯æ‰“ç æ•ˆæœ
                mosaic_applied = False
                for region in valid_regions:
                    x, y, w, h = region.bbox
                    
                    # æå–åŸå§‹å’Œå¤„ç†åçš„åŒºåŸŸ
                    original_roi = original_frame[y:y+h, x:x+w]
                    processed_roi = processed_frame[y:y+h, x:x+w]
                    
                    # è®¡ç®—å·®å¼‚
                    diff = cv2.absdiff(original_roi, processed_roi)
                    diff_score = np.mean(diff)
                    
                    if diff_score > 1.0:  # æœ‰æ˜æ˜¾å·®å¼‚è¯´æ˜æ‰“ç ç”Ÿæ•ˆ
                        mosaic_applied = True
                        break
                
                if not mosaic_applied:
                    issues.append("æ‰“ç æ•ˆæœä¸æ˜æ˜¾ï¼Œå¯èƒ½æœªæ­£ç¡®åº”ç”¨")
                
                # ä¿å­˜éªŒè¯ç»“æœå›¾ç‰‡
                output_path = os.path.join(self.output_dir, "mosaic_validation_sample.jpg")
                
                # ç»˜åˆ¶æ£€æµ‹æ¡†å’Œæ‰“ç åŒºåŸŸ
                visualization = processed_frame.copy()
                for i, region in enumerate(valid_regions):
                    x, y, w, h = region.bbox
                    cv2.rectangle(visualization, (x, y), (x+w, y+h), (0, 255, 0), 2)
                    cv2.putText(visualization, f"Region {i+1}", (x, y-10), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
                
                cv2.imwrite(output_path, visualization)
                
            except Exception as e:
                issues.append(f"æ‰“ç åº”ç”¨å¤±è´¥: {str(e)}")
            
            status = "fail" if issues else "pass"
            message = "; ".join(issues) if issues else "æ‰“ç åº”ç”¨éªŒè¯é€šè¿‡"
            
            details = {
                "frame_info": {
                    "path": sample_frame_path,
                    "resolution": f"{frame_width}x{frame_height}"
                },
                "regions_info": {
                    "total_regions": len(regions),
                    "valid_regions": len(valid_regions), 
                    "invalid_regions": len(invalid_regions)
                },
                "mosaic_settings": {
                    "strength": mosaic_strength,
                    "applied": mosaic_applied if 'mosaic_applied' in locals() else False
                },
                "output_sample": output_path if 'output_path' in locals() else None,
                "issues": issues
            }
            
            result = ValidationResult(
                stage="mosaic_application",
                status=status,
                message=message, 
                details=details
            )
            
            self.validation_results.append(result)
            return result
            
        except Exception as e:
            result = ValidationResult(
                stage="mosaic_application",
                status="fail",
                message=f"éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}"
            )
            self.validation_results.append(result)
            return result
    
    def validate_end_to_end_coverage(
        self,
        video_path: str,
        output_video_path: str, 
        sample_frames: List[int] = None
    ) -> ValidationResult:
        """éªŒè¯ç«¯åˆ°ç«¯çš„å¸§è¦†ç›–æƒ…å†µ
        
        Args:
            video_path: åŸå§‹è§†é¢‘è·¯å¾„
            output_video_path: å¤„ç†åè§†é¢‘è·¯å¾„
            sample_frames: æŠ½æ ·æ£€æŸ¥çš„å¸§å·åˆ—è¡¨ï¼Œé»˜è®¤éšæœºé€‰æ‹©
            
        Returns:
            éªŒè¯ç»“æœ
        """
        try:
            issues = []
            
            # æ‰“å¼€åŸå§‹å’Œå¤„ç†åçš„è§†é¢‘
            original_cap = cv2.VideoCapture(video_path)
            processed_cap = cv2.VideoCapture(output_video_path)
            
            if not original_cap.isOpened():
                return ValidationResult(
                    stage="end_to_end_coverage",
                    status="fail",
                    message=f"æ— æ³•æ‰“å¼€åŸå§‹è§†é¢‘: {video_path}"
                )
            
            if not processed_cap.isOpened():
                return ValidationResult(
                    stage="end_to_end_coverage", 
                    status="fail",
                    message=f"æ— æ³•æ‰“å¼€å¤„ç†åè§†é¢‘: {output_video_path}"
                )
            
            # è·å–è§†é¢‘ä¿¡æ¯
            total_frames = int(original_cap.get(cv2.CAP_PROP_FRAME_COUNT))
            processed_frames = int(processed_cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            if total_frames != processed_frames:
                issues.append(f"å¸§æ•°ä¸åŒ¹é…: åŸå§‹{total_frames}, å¤„ç†å{processed_frames}")
            
            # é€‰æ‹©æŠ½æ ·å¸§
            if sample_frames is None:
                # éšæœºé€‰æ‹©20å¸§è¿›è¡Œæ£€æŸ¥
                sample_count = min(20, total_frames)
                sample_frames = sorted(np.random.choice(total_frames, sample_count, replace=False))
            
            # é€å¸§æ¯”è¾ƒ
            frames_with_changes = 0
            frames_without_changes = 0
            comparison_results = []
            
            for frame_idx in sample_frames:
                # å®šä½åˆ°æŒ‡å®šå¸§
                original_cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
                processed_cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
                
                ret1, orig_frame = original_cap.read()
                ret2, proc_frame = processed_cap.read()
                
                if not (ret1 and ret2):
                    continue
                
                # è®¡ç®—å¸§å·®å¼‚
                diff = cv2.absdiff(orig_frame, proc_frame)
                diff_score = np.mean(diff)
                
                has_changes = diff_score > 1.0
                if has_changes:
                    frames_with_changes += 1
                else:
                    frames_without_changes += 1
                
                comparison_results.append({
                    "frame_id": frame_idx + 1,
                    "diff_score": float(diff_score),
                    "has_changes": has_changes
                })
            
            original_cap.release()
            processed_cap.release()
            
            # åˆ†æç»“æœ
            total_sampled = len(comparison_results)
            change_rate = frames_with_changes / total_sampled if total_sampled > 0 else 0
            
            # æ ¹æ®å˜åŒ–ç‡åˆ¤æ–­æ˜¯å¦åˆç†
            if change_rate < 0.1:  # å°äº10%çš„å¸§æœ‰å˜åŒ–
                issues.append(f"æ‰“ç è¦†ç›–ç‡è¿‡ä½: åªæœ‰{change_rate:.1%}çš„å¸§æœ‰å˜åŒ–")
            elif change_rate > 0.8:  # è¶…è¿‡80%çš„å¸§æœ‰å˜åŒ–
                issues.append(f"æ‰“ç è¦†ç›–ç‡è¿‡é«˜: {change_rate:.1%}çš„å¸§æœ‰å˜åŒ–ï¼Œå¯èƒ½å­˜åœ¨è¯¯æ£€")
            
            status = "fail" if issues else "pass"
            message = "; ".join(issues) if issues else "ç«¯åˆ°ç«¯è¦†ç›–éªŒè¯é€šè¿‡"
            
            details = {
                "video_comparison": {
                    "original_frames": total_frames,
                    "processed_frames": processed_frames,
                    "sampled_frames": total_sampled
                },
                "coverage_analysis": {
                    "frames_with_changes": frames_with_changes,
                    "frames_without_changes": frames_without_changes, 
                    "change_rate": f"{change_rate:.1%}"
                },
                "sample_results": comparison_results[:10],  # å‰10ä¸ªç»“æœä½œä¸ºæ ·æœ¬
                "issues": issues
            }
            
            result = ValidationResult(
                stage="end_to_end_coverage",
                status=status,
                message=message,
                details=details
            )
            
            self.validation_results.append(result)
            return result
            
        except Exception as e:
            result = ValidationResult(
                stage="end_to_end_coverage",
                status="fail", 
                message=f"éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}"
            )
            self.validation_results.append(result)
            return result

    def _generate_recommendations(self) -> List[str]:
        """æ ¹æ®éªŒè¯ç»“æœç”Ÿæˆä¿®å¤å»ºè®®"""
        recommendations = []
        
        failed_stages = [r.stage for r in self.validation_results if r.status == "fail"]
        
        if "frame_extraction" in failed_stages:
            recommendations.append("å»ºè®®æ£€æŸ¥å¸§æå–å‚æ•°ï¼Œç¡®ä¿é‡‡æ ·ç‡å’Œå¸§æ•°è®¾ç½®åˆç†")
        
        if "llm_detection" in failed_stages:
            recommendations.append("å»ºè®®ä¼˜åŒ–LLMæ£€æµ‹æç¤ºè¯ï¼Œæˆ–è°ƒæ•´æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼")
            
        if "coordinate_conversion" in failed_stages:
            recommendations.append("å»ºè®®æ£€æŸ¥åæ ‡è½¬æ¢é€»è¾‘ï¼Œç¡®ä¿ç¼©æ”¾å› å­è®¡ç®—æ­£ç¡®")
            
        if "tracking_interpolation" in failed_stages:
            recommendations.append("å»ºè®®ä¼˜åŒ–æ’å€¼ç®—æ³•ï¼Œæˆ–å¢åŠ å…³é”®å¸§å¯†åº¦")
            
        if "mosaic_application" in failed_stages:
            recommendations.append("å»ºè®®æ£€æŸ¥æ‰“ç å‡½æ•°å®ç°ï¼Œç¡®ä¿åæ ‡å’Œå¼ºåº¦å‚æ•°æ­£ç¡®")
            
        if "end_to_end_coverage" in failed_stages:
            recommendations.append("å»ºè®®è¿›è¡Œå®Œæ•´çš„ç«¯åˆ°ç«¯æµ‹è¯•ï¼Œæ£€æŸ¥æ•´ä¸ªæµç¨‹çš„ä¸€è‡´æ€§")
        
        return recommendations