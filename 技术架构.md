-----
## 加上视频的架构方案
-----
# 基于LLM+工具函数的视频处理Agent技术架构

## 1. 整体架构概览

### 1.1 架构原则
- **职责分离**: LLM负责理解分析，工具函数负责执行处理
- **MVP优先**: 核心功能先行，性能优化后续迭代
- **扩展性**: 模块化设计，便于添加新功能
- **标准化**: 统一的工具接口和数据格式

### 1.2 系统架构图
```
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│   用户输入      │───▶│   Agent核心      │───▶│   工具函数库    │
│ "视频打码需求"  │    │  (Gemini LLM)    │    │ (视频处理工具)   │
└─────────────────┘    └──────────────────┘    └─────────────────┘
                              │                         │
                              ▼                         ▼
                       ┌──────────────┐        ┌─────────────────┐
                       │ 意图理解     │        │ 视频帧提取      │
                       │ 任务拆解     │        │ 区域检测        │
                       │ 工具调度     │        │ 打码处理        │
                       └──────────────┘        │ 视频重建        │
                                              └─────────────────┘
```

## 2. 技术栈选型

### 2.1 核心依赖
```bash
# LLM相关
google-genai==0.3.2           # 原生Gemini SDK
python-dotenv==1.0.0          # 环境变量管理

# 视频处理
opencv-python==4.8.1.78       # 视频读写和基础处理
pillow==10.1.0                # 图像处理
numpy==1.24.3                 # 数值计算

# 开发工具
fastapi==0.104.1              # API服务(可选)
pydantic==2.5.0               # 数据验证
```

### 2.2 系统要求
- Python 3.12+
- 内存: 建议8GB+
- 硬盘: 处理视频需要足够临时空间
- GPU: 可选，用于加速视频处理

## 3. 模块设计

### 3.1 项目结构
```
video_agent_mvp/
├── README.md
├── requirements.txt
├── pyproject.toml             # uv项目配置文件
├── .env.example
├── config.py                 # 配置管理
├── main.py                   # 程序入口
│
├── core/                     # 核心模块
│   ├── __init__.py
│   ├── agent.py              # Agent主类
│   ├── llm_client.py         # LLM客户端封装
│   └── exceptions.py         # 自定义异常
│
├── tools/                    # 工具函数模块
│   ├── __init__.py
│   ├── registry.py           # 工具注册机制
│   ├── video_tools.py        # 视频处理工具
│   └── image_tools.py        # 图像处理工具
│
├── utils/                    # 工具模块
│   ├── __init__.py
│   ├── video_processor.py    # 视频处理核心
│   ├── file_manager.py       # 文件管理
│   └── logger.py             # 日志管理
│
├── tests/                    # 测试模块
│   ├── __init__.py
│   ├── test_tools.py
│   └── test_video_processor.py
│
└── examples/                 # 示例和演示
    ├── sample_videos/
    ├── demo.py
    └── api_server.py
```

### 3.2 核心模块设计

#### 3.2.1 Agent核心类
```python
class VideoAgent:
    """视频处理智能代理核心类"""
    
    def __init__(self, api_key: str):
        self.llm_client = GeminiClient(api_key)
        self.tool_registry = ToolRegistry()
        self._register_default_tools()
    
    async def process_request(self, user_input: str, video_path: str) -> str:
        """处理用户请求的主流程"""
        
    def _register_default_tools(self):
        """注册默认工具函数"""
```

#### 3.2.2 工具注册机制
```python
class ToolRegistry:
    """工具函数注册和管理"""
    
    def register(self, func: Callable) -> Callable:
        """装饰器：注册工具函数"""
        
    def get_tool_descriptions(self) -> List[Dict]:
        """获取所有工具的描述信息，供LLM使用"""
        
    def execute_tool(self, tool_name: str, **kwargs) -> Any:
        """执行指定的工具函数"""
```

#### 3.2.3 视频处理核心
```python
class VideoProcessor:
    """视频处理核心功能"""
    
    def extract_frames(self, video_path: str, sample_rate: int) -> List[str]:
        """提取视频关键帧"""
        
    def apply_mosaic_regions(self, video_path: str, regions_data: List[Dict]) -> str:
        """对指定区域应用打码效果"""
        
    def rebuild_video(self, frames_dir: str, output_path: str, fps: float) -> str:
        """重建视频文件"""
```

## 4. 工具函数接口规范

### 4.1 工具函数标准格式
```python
@tool_registry.register
def tool_function_name(
    param1: type,
    param2: type = default_value
) -> return_type:
    """清晰的功能描述
    
    Args:
        param1: 参数1的详细描述
        param2: 参数2的详细描述，包含默认值说明
        
    Returns:
        返回值的详细描述
        
    Raises:
        SpecificException: 特定异常的描述
    """
    # 实现逻辑
    pass
```

### 4.2 核心工具函数定义

#### 4.2.1 视频帧提取工具
```python
@tool_registry.register
def extract_video_frames(
    video_path: str,
    sample_rate: int = 30,
    max_frames: int = 20
) -> str:
    """提取视频关键帧供LLM分析
    
    Args:
        video_path: 视频文件的完整路径
        sample_rate: 采样率，每N帧提取一帧
        max_frames: 最大提取帧数，防止视频过长
        
    Returns:
        JSON字符串，包含提取的帧信息
        格式: {"frames": [{"frame_id": 1, "timestamp": 0.5, "image_path": "/tmp/frame_1.jpg"}]}
    """
```

#### 4.2.2 视频区域打码工具
```python
@tool_registry.register
def mosaic_video_regions(
    video_path: str,
    regions_data: str,
    mosaic_strength: int = 15,
    tracking_enabled: bool = True
) -> str:
    """对视频指定区域进行打码处理
    
    Args:
        video_path: 源视频文件路径
        regions_data: LLM分析得到的区域信息，JSON格式字符串
        mosaic_strength: 打码强度(5-50)，数值越大越模糊
        tracking_enabled: 是否启用简单追踪优化
        
    Returns:
        处理后的视频文件路径
        
    Raises:
        VideoProcessingError: 视频处理失败时抛出
    """
```

#### 4.2.3 视频信息获取工具
```python
@tool_registry.register
def get_video_info(video_path: str) -> str:
    """获取视频基本信息
    
    Args:
        video_path: 视频文件路径
        
    Returns:
        JSON格式的视频信息字符串
        包含: 时长、分辨率、帧率、文件大小等
    """
```

## 5. 数据流设计

### 5.1 主要数据结构

#### 5.1.1 帧信息结构
```python
@dataclass
class FrameInfo:
    frame_id: int           # 帧序号
    timestamp: float        # 时间戳(秒)
    image_path: str         # 帧图片保存路径
    width: int              # 帧宽度
    height: int             # 帧高度
```

#### 5.1.2 检测区域结构
```python
@dataclass
class DetectionRegion:
    frame_id: int           # 所属帧ID
    object_type: str        # 检测对象类型(text/object/face等)
    bbox: Tuple[int, int, int, int]  # 边界框(x, y, width, height)
    confidence: float       # 置信度(0-1)
    description: str        # 对象描述
    track_id: Optional[int] = None   # 追踪ID(可选)
```

#### 5.1.3 处理任务结构
```python
@dataclass
class ProcessingTask:
    task_id: str           # 任务唯一标识
    video_path: str        # 源视频路径
    target_description: str # 目标描述
    regions: List[DetectionRegion]  # 检测到的区域
    status: str            # 任务状态
    output_path: Optional[str] = None  # 输出文件路径
```

### 5.2 数据流转过程

```
1. 用户输入 → 标准化处理
   Input: "这个视频里的手机需要打码"
   Output: ProcessingTask对象

2. 视频帧提取 → 关键帧数据
   Input: video_path, sample_rate
   Output: List[FrameInfo]

3. LLM分析 → 检测结果
   Input: 帧图片 + 目标描述
   Output: List[DetectionRegion]

4. 区域处理 → 打码视频
   Input: video_path + regions_data
   Output: processed_video_path

5. 结果返回 → 用户反馈
   Input: 处理结果
   Output: 成功消息 + 文件路径
```

## 6. LLM交互设计

### 6.1 Prompt模板设计

#### 6.1.1 视频分析Prompt
```python
VIDEO_ANALYSIS_PROMPT = """
你是一个专业的视频内容分析助手。请仔细分析提供的视频帧，准确识别用户指定的目标对象。

任务要求:
1. 识别目标: {target_description}
2. 返回精确的边界框坐标
3. 评估检测置信度
4. 标注对象在不同帧间的变化

输出格式要求:
必须返回JSON格式，结构如下:
{{
  "detections": [
    {{
      "frame_id": 1,
      "objects": [
        {{
          "type": "目标类型",
          "bbox": [x, y, width, height],
          "confidence": 0.95,
          "description": "具体描述"
        }}
      ]
    }}
  ],
  "summary": "整体分析总结"
}}

视频帧信息:
{frame_data}

请开始分析:
"""
```

#### 6.1.2 任务分解Prompt
```python
TASK_DECOMPOSITION_PROMPT = """
用户请求: {user_request}
视频信息: {video_info}

请将用户请求分解为具体的执行步骤，并选择合适的工具函数。

可用工具:
{available_tools}

请返回执行计划的JSON格式:
{{
  "steps": [
    {{
      "step_id": 1,
      "description": "步骤描述",
      "tool_name": "工具函数名",
      "parameters": {{"param1": "value1"}}
    }}
  ]
}}
"""
```

### 6.2 LLM客户端封装
```python
class GeminiClient:
    """Gemini LLM客户端封装"""
    
    def __init__(self, api_key: str):
        self.client = genai.Client(api_key=api_key)
        self.model = "gemini-2.0-flash"
    
    async def analyze_video_frames(
        self, 
        frames: List[FrameInfo], 
        target_description: str
    ) -> List[DetectionRegion]:
        """分析视频帧，返回检测结果"""
        
    async def decompose_task(
        self, 
        user_request: str, 
        available_tools: List[Dict]
    ) -> List[Dict]:
        """分解用户任务为执行步骤"""
```

## 7. 性能优化策略

### 7.1 帧采样优化
```python
class SmartSampler:
    """智能帧采样器"""
    
    def calculate_sample_rate(self, video_duration: float, target_type: str) -> int:
        """根据视频时长和目标类型计算采样率"""
        
    def detect_scene_changes(self, video_path: str) -> List[float]:
        """检测场景变化时间点，在变化处密集采样"""
```

### 7.2 追踪优化
```python
class SimpleTracker:
    """简单的对象追踪器"""
    
    def interpolate_regions(
        self, 
        keyframe_regions: List[DetectionRegion], 
        total_frames: int
    ) -> List[DetectionRegion]:
        """在关键帧之间插值生成中间帧的区域信息"""
        
    def smooth_trajectories(self, regions: List[DetectionRegion]) -> List[DetectionRegion]:
        """平滑对象轨迹，减少抖动"""
```

### 7.3 内存管理
```python
class ResourceManager:
    """资源管理器"""
    
    def __init__(self, max_memory_mb: int = 2048):
        self.max_memory = max_memory_mb
        self.temp_files = []
    
    def process_video_in_chunks(self, video_path: str, chunk_size: int = 300):
        """分块处理大视频文件"""
        
    def cleanup_temp_files(self):
        """清理临时文件"""
```

## 8. 错误处理和日志

### 8.1 异常体系
```python
class VideoAgentException(Exception):
    """Agent基础异常"""

class VideoProcessingError(VideoAgentException):
    """视频处理相关错误"""

class LLMAnalysisError(VideoAgentException):
    """LLM分析相关错误"""

class ToolExecutionError(VideoAgentException):
    """工具执行相关错误"""
```

### 8.2 日志配置
```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('video_agent.log'),
        logging.StreamHandler()
    ]
)
```

## 9. 配置管理

### 9.1 配置文件结构

#### pyproject.toml
```toml
[project]
name = "video-agent-mvp"
version = "0.1.0"
description = "基于LLM+工具函数的视频处理Agent"
authors = [
    {name = "Your Name", email = "your.email@example.com"}
]
dependencies = [
    "google-genai==0.3.2",
    "opencv-python==4.8.1.78",
    "pillow>=10.1.0",
    "numpy>=1.24.3",
    "python-dotenv>=1.0.0",
    "pydantic>=2.5.0",
    "fastapi>=0.104.1",
]
requires-python = ">=3.12"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.uv]
dev-dependencies = [
    "pytest>=7.4.0",
    "pytest-asyncio>=0.21.0",
    "black>=23.0.0",
    "ruff>=0.1.0",
]
```

#### config.py
```python
import os
from dataclasses import dataclass

@dataclass
class Config:
    # LLM配置
    GEMINI_API_KEY: str = os.getenv("GEMINI_API_KEY")
    GEMINI_MODEL: str = "gemini-2.0-flash"
    
    # 视频处理配置
    MAX_VIDEO_DURATION: int = 300  # 最大支持视频时长(秒)
    DEFAULT_SAMPLE_RATE: int = 30  # 默认采样率
    MAX_FRAMES_PER_REQUEST: int = 20  # 单次LLM请求最大帧数
    
    # 输出配置
    OUTPUT_DIR: str = "output"
    TEMP_DIR: str = "temp"
    LOG_LEVEL: str = "INFO"
    
    # 性能配置
    MAX_MEMORY_MB: int = 2048
    ENABLE_GPU: bool = True
    CONCURRENT_WORKERS: int = 4
```

## 10. 部署和运维

### 10.1 环境准备

#### 使用uv快速设置
```bash
# 1. 安装uv（如果未安装）
curl -LsSf https://astral.sh/uv/install.sh | sh
# 或者使用pip: pip install uv

# 2. 初始化项目
uv init video-agent-mvp
cd video-agent-mvp

# 3. 设置Python版本
uv python pin 3.12

# 4. 安装项目依赖
uv sync

# 5. 激活虚拟环境
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# 6. 配置环境变量
cp .env.example .env
# 编辑.env文件，添加GEMINI_API_KEY
```

#### 依赖管理
```bash
# 添加新依赖
uv add package-name

# 添加开发依赖
uv add --dev pytest

# 更新依赖
uv sync --upgrade

# 生成requirements.txt（如需要）
uv pip freeze > requirements.txt
```

### 10.2 运行方式

#### 10.2.1 开发环境运行
```bash
# 确保在项目根目录且虚拟环境已激活
uv run python main.py --video "path/to/video.mp4" --request "对视频中的手机进行打码"
```

#### 10.2.2 API服务模式
```bash
uv run python examples/api_server.py
# 启动FastAPI服务，提供HTTP接口
```

#### 10.2.3 交互式模式
```bash
uv run python examples/demo.py
# 启动交互式演示程序
```



### 10.3 监控和维护
```python
# 性能监控
class PerformanceMonitor:
    def track_processing_time(self, video_path: str, duration: float):
        """记录处理时间"""
        
    def track_memory_usage(self):
        """监控内存使用"""
        
    def generate_report(self) -> Dict:
        """生成性能报告"""
```

## 11. 扩展性设计

### 11.1 新工具函数添加
```python
# 添加新的图像处理工具
@tool_registry.register
def video_face_blur(video_path: str, blur_strength: int = 15) -> str:
    """人脸模糊处理"""
    pass

# 添加新的音频处理工具  
@tool_registry.register
def video_audio_filter(video_path: str, filter_type: str) -> str:
    """音频过滤处理"""
    pass
```

### 11.2 多模型支持
```python
class LLMFactory:
    """LLM工厂类，支持多种模型"""
    
    @staticmethod
    def create_client(model_type: str, **kwargs):
        if model_type == "gemini":
            return GeminiClient(**kwargs)
        elif model_type == "openai":
            return OpenAIClient(**kwargs)
        # 可扩展其他模型
```

### 11.3 插件系统
```python
class PluginManager:
    """插件管理器"""
    
    def load_plugin(self, plugin_path: str):
        """动态加载插件"""
        
    def register_custom_tool(self, tool_func: Callable):
        """注册自定义工具"""
```

---

## 总结

这个技术架构设计遵循 MVP 原则，通过 LLM 负责"理解"、工具函数负责"执行"的分工模式，实现了灵活而高效的视频处理能力。核心特点包括：

1. **清晰的职责分离**: LLM 专注内容理解，工具专注高性能处理
2. **模块化设计**: 各模块职责单一，便于维护和扩展
3. **标准化接口**: 统一的工具注册和调用机制
4. **性能优化**: 智能采样、追踪优化、资源管理
5. **扩展友好**: 易于添加新功能和支持新模型

该架构可以作为视频处理 Agent 系统的技术基础，支持从简单的打码需求到复杂的视频内容分析任务。
