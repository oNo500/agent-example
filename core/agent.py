from typing import Dict, List, Any, Optional
import logging
import asyncio
import json
import os
from pydantic import BaseModel, Field
from core.llm_client import GeminiClient, FrameInfo, DetectionRegion
from tools.registry import tool_registry
from core.exceptions import VideoAgentException, ConfigurationError
from config import Config

class ProcessingTask(BaseModel):
    """å¤„ç†ä»»åŠ¡æ¨¡å‹"""
    task_id: str = Field(..., description="ä»»åŠ¡ID")
    video_path: str = Field(..., description="è§†é¢‘è·¯å¾„")
    target_description: str = Field(..., description="ç›®æ ‡æè¿°")
    regions: List[DetectionRegion] = Field(default_factory=list, description="æ£€æµ‹åŒºåŸŸåˆ—è¡¨")
    status: str = Field(..., description="ä»»åŠ¡çŠ¶æ€")
    output_path: Optional[str] = Field(None, description="è¾“å‡ºè·¯å¾„")

class VideoAgent:
    """è§†é¢‘å¤„ç†æ™ºèƒ½ä»£ç†æ ¸å¿ƒç±»"""
    
    def __init__(self, api_key: str = None):
        """åˆå§‹åŒ–VideoAgent
        
        Args:
            api_key: Gemini APIå¯†é’¥ï¼Œå¦‚æœä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
        """
        self.config = Config()
        self.llm_client = GeminiClient(api_key)
        self.tool_registry = tool_registry  # ä½¿ç”¨å…¨å±€å·¥å…·æ³¨å†Œå®ä¾‹
        self.logger = self._setup_logger()
        
        # æ³¨å†Œé»˜è®¤å·¥å…·
        self._register_default_tools()
        
        self.logger.info("VideoAgent initialized successfully")
    
    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—é…ç½®"""
        logger = logging.getLogger(__name__)
        logger.setLevel(getattr(logging, self.config.log_level))
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def _register_default_tools(self):
        """æ³¨å†Œé»˜è®¤å·¥å…·å‡½æ•°"""
        # å¯¼å…¥å·¥å…·æ¨¡å—ï¼Œè§¦å‘å·¥å…·æ³¨å†Œ
        try:
            from tools import video_tools
            from tools import annotation_tools
            tool_count = len(self.tool_registry.list_tools())
            self.logger.info(f"Registered {tool_count} video processing and annotation tools")
        except ImportError as e:
            self.logger.warning(f"Failed to import tools: {e}")
    
    async def process_request(self, user_input: str, video_path: str) -> str:
        """å¤„ç†ç”¨æˆ·è¯·æ±‚çš„ä¸»æµç¨‹
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥çš„å¤„ç†éœ€æ±‚
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            å¤„ç†ç»“æœæè¿°
            
        Raises:
            VideoAgentException: å¤„ç†è¿‡ç¨‹ä¸­çš„å„ç§å¼‚å¸¸
        """
        try:
            self.logger.info(f"Processing request: {user_input}")
            self.logger.info(f"Video path: {video_path}")
            
            # æ­¥éª¤1: è·å–è§†é¢‘åŸºæœ¬ä¿¡æ¯
            video_info = await self._get_video_info(video_path)
            self.logger.info(f"Video info: {video_info}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡æ³¨ç±»ä»»åŠ¡ï¼ˆæ‰‹æœºæ‰“ç ã€ç‰©ä½“é®æŒ¡ç­‰ï¼‰
            annotation_keywords = ["æ‰“ç ", "é®æŒ¡", "é©¬èµ›å…‹", "éšç§", "æ ‡æ³¨", "æ‰‹æœº", "äººè„¸"]
            is_annotation_task = any(keyword in user_input for keyword in annotation_keywords)
            
            if is_annotation_task:
                # å¯¹äºæ ‡æ³¨ç±»ä»»åŠ¡ï¼Œç›´æ¥åˆ›å»ºæ ‡æ³¨å·¥ä½œæµ
                self.logger.info("Detected annotation task, creating manual annotation workflow")
                
                # æå–ç›®æ ‡æè¿°
                target_description = "æ‰‹æœº"  # é»˜è®¤
                if "äººè„¸" in user_input:
                    target_description = "äººè„¸"
                elif "æ‰‹æœº" in user_input:
                    target_description = "æ‰‹æœº"
                
                # å…ˆæ£€æŸ¥æ˜¯å¦å·²æœ‰æ ‡æ³¨æ•°æ®
                existing_sessions = self.tool_registry.execute_tool("list_annotation_sessions")
                sessions_data = json.loads(existing_sessions)
                
                # æŸ¥æ‰¾ç›¸åŒè§†é¢‘çš„æ ‡æ³¨ä¼šè¯
                matching_session = None
                for session in sessions_data.get("sessions", []):
                    if session.get("video_path") == video_path:
                        matching_session = session
                        break
                
                if matching_session:
                    # é¦–å…ˆå°è¯•è‡ªåŠ¨ä¿å­˜ä¸‹è½½çš„æ ‡æ³¨æ–‡ä»¶
                    self.logger.info("Trying to auto-save downloaded annotation file")
                    auto_save_result = self.tool_registry.execute_tool(
                        "auto_save_downloaded_regions",
                        session_id=matching_session["session_id"]
                    )
                    auto_save_data = json.loads(auto_save_result)
                    
                    if auto_save_data.get("status") == "success":
                        self.logger.info("Successfully auto-saved downloaded annotation file")
                    
                    # å°è¯•åŠ è½½æ ‡æ³¨æ•°æ®
                    annotation_data = self.tool_registry.execute_tool(
                        "load_annotation_data", 
                        session_id=matching_session["session_id"]
                    )
                    annotation_result = json.loads(annotation_data)
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æ ‡æ³¨æ•°æ®
                    regions_list = annotation_result.get("regions", [])
                    has_valid_regions = (
                        annotation_result.get("status") != "no_annotation" and 
                        isinstance(regions_list, list) and 
                        len(regions_list) > 0
                    )
                    
                    if has_valid_regions:
                        # æœ‰æœ‰æ•ˆæ ‡æ³¨æ•°æ®ï¼Œä½¿ç”¨LLMè¿½è¸ªå¢å¼ºåæ‰§è¡Œæ‰“ç å¤„ç†
                        self.logger.info(f"Found valid annotation data with {len(regions_list)} regions, enhancing with LLM tracking")
                        
                        # è½¬æ¢ä¸ºDetectionRegionå¯¹è±¡ä½œä¸ºç§å­
                        seed_regions = []
                        for region_data in regions_list:
                            seed_region = DetectionRegion(
                                frame_id=region_data["frame_id"],
                                object_type=region_data.get("object_type", target_description),
                                bbox=tuple(region_data["bbox"]),
                                confidence=region_data.get("confidence", 1.0),
                                description=region_data.get("description", f"{target_description}åŒºåŸŸ - æ‰‹åŠ¨æ ‡æ³¨")
                            )
                            seed_regions.append(seed_region)
                        
                        # ä½¿ç”¨LLMè¿½è¸ªå¢å¼ºæ ‡æ³¨
                        enhanced_regions = await self.enhance_annotation_with_tracking(
                            video_path, seed_regions, target_description
                        )
                        
                        # è½¬æ¢å›JSONæ ¼å¼ç”¨äºæ‰“ç 
                        enhanced_regions_data = {
                            "regions": [
                                {
                                    "frame_id": region.frame_id,
                                    "object_type": region.object_type,
                                    "bbox": list(region.bbox),
                                    "confidence": region.confidence,
                                    "description": region.description,
                                    "track_id": region.track_id
                                }
                                for region in enhanced_regions
                            ]
                        }
                        
                        self.logger.info(f"Enhanced tracking complete: {len(enhanced_regions)} total regions for mosaic processing")
                        regions_data = json.dumps(enhanced_regions_data)
                        output_path = self.tool_registry.execute_tool(
                            "mosaic_video_regions",
                            video_path=video_path,
                            regions_data=regions_data,
                            mosaic_strength=15
                        )
                        
                        # æä¾›å®Œæˆåçš„å‹å¥½æç¤º
                        return f"""
âœ… æ™ºèƒ½è¿½è¸ªæ ‡æ³¨æµç¨‹å®Œæˆï¼

ğŸ¯ ç§å­æ ‡æ³¨: {len(regions_list)} ä¸ªæ‰‹åŠ¨æ ‡æ³¨åŒºåŸŸ
ğŸ¤– LLMè¿½è¸ª: å…±è¯†åˆ« {len(enhanced_regions)} ä¸ªè¿½è¸ªåŒºåŸŸ
ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}
ğŸš€ ä½¿ç”¨äº†çœŸæ­£çš„LLMå¤šå¸§åˆ†ææŠ€æœ¯ï¼Œæ™ºèƒ½è¿½è¸ªç›®æ ‡è¿åŠ¨è½¨è¿¹

ğŸ’¡ æŠ€æœ¯ä¼˜åŠ¿: ç»“åˆæ‰‹åŠ¨æ ‡æ³¨ç²¾ç¡®åº¦å’ŒLLMè¿½è¸ªèƒ½åŠ›ï¼Œé€‚åº”ç›®æ ‡åœ¨è§†é¢‘ä¸­çš„ä½ç½®å˜åŒ–ï¼
                        """.strip()
                    else:
                        # æ ‡æ³¨ä¼šè¯å­˜åœ¨ä½†æ²¡æœ‰å®Œæˆæ ‡æ³¨ï¼Œæä¾›æ¸…æ™°æŒ‡å¼•
                        session_id = matching_session["session_id"]
                        annotation_file = os.path.join(
                            self.config.OUTPUT_DIR, 
                            "annotations", 
                            session_id, 
                            "annotation.html"
                        )
                        
                        return f"""
â³ å‘ç°å·²æœ‰æ ‡æ³¨ä¼šè¯ä½†å°šæœªå®Œæˆæ ‡æ³¨

ğŸ“‹ ä¼šè¯ID: {session_id}
ğŸ¯ ç›®æ ‡: {target_description}
ğŸ“ æ ‡æ³¨ç•Œé¢: {annotation_file}

ğŸ“ ä¸‹ä¸€æ­¥æ“ä½œ:
1. æ‰“å¼€ä¸Šè¿°HTMLæ–‡ä»¶ï¼ˆæˆ–é‡æ–°è¿è¡Œç¨‹åºè‡ªåŠ¨æ‰“å¼€ï¼‰
2. åœ¨å›¾ç‰‡ä¸Šç‚¹å‡»æ‹–æ‹½æ ‡æ³¨{target_description}åŒºåŸŸ
3. ç‚¹å‡»"ä¿å­˜æ ‡æ³¨æ•°æ®"ä¸‹è½½regions.jsonæ–‡ä»¶
4. å°†ä¸‹è½½çš„æ–‡ä»¶å¤åˆ¶åˆ°æ ‡æ³¨ä¼šè¯ç›®å½•
5. é‡æ–°è¿è¡Œæ­¤ç¨‹åºå®Œæˆæ‰“ç å¤„ç†

ğŸ’¡ æç¤º: åªéœ€æ ‡æ³¨ä¸€å¼ å›¾ç‰‡ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨åº”ç”¨åˆ°æ•´ä¸ªè§†é¢‘ï¼
                        """.strip()
                
                # æ²¡æœ‰ç°æœ‰æ ‡æ³¨æ•°æ®ï¼Œåˆ›å»ºæ–°çš„æ ‡æ³¨å·¥ä½œæµ
                workflow_result = await self.create_manual_annotation_workflow(
                    video_path, target_description
                )
                workflow_data = json.loads(workflow_result)
                return workflow_data.get("message", "æ ‡æ³¨å·¥ä½œæµå·²åˆ›å»º")
            
            else:
                # å¯¹äºå…¶ä»–ä»»åŠ¡ï¼Œä½¿ç”¨åŸæœ‰çš„LLMåˆ†è§£æµç¨‹
                # æ­¥éª¤2: åˆ†è§£ä»»åŠ¡
                available_tools = self.tool_registry.get_tool_descriptions()
                task_steps = await self.llm_client.decompose_task(
                    user_input, available_tools, video_info
                )
                self.logger.info(f"Task decomposed into {len(task_steps)} steps")
                
                # æ­¥éª¤3: æ‰§è¡Œä»»åŠ¡æ­¥éª¤
                result = await self._execute_task_steps(task_steps, video_path, user_input)
                
                self.logger.info("Request processed successfully")
                return result
            
        except Exception as e:
            self.logger.error(f"Failed to process request: {str(e)}")
            raise VideoAgentException(f"Processing failed: {str(e)}") from e
    
    async def _get_video_info(self, video_path: str) -> Dict:
        """è·å–è§†é¢‘åŸºæœ¬ä¿¡æ¯"""
        try:
            if self.tool_registry.has_tool("get_video_info"):
                info_str = self.tool_registry.execute_tool("get_video_info", video_path=video_path)
                import json
                return json.loads(info_str)
            else:
                # å¦‚æœæ²¡æœ‰æ³¨å†Œå·¥å…·ï¼Œè¿”å›åŸºæœ¬ä¿¡æ¯
                return {
                    "path": video_path,
                    "status": "info_unavailable"
                }
        except Exception as e:
            self.logger.warning(f"Failed to get video info: {str(e)}")
            return {"path": video_path, "error": str(e)}
    
    async def _execute_task_steps(
        self, 
        task_steps: List[Dict], 
        video_path: str, 
        user_input: str
    ) -> str:
        """æ‰§è¡Œä»»åŠ¡æ­¥éª¤
        
        Args:
            task_steps: ä»»åŠ¡æ­¥éª¤åˆ—è¡¨
            video_path: è§†é¢‘è·¯å¾„
            user_input: ç”¨æˆ·è¾“å…¥
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        results = []
        
        for i, step in enumerate(task_steps):
            try:
                self.logger.info(f"Executing step {i+1}: {step.get('description', 'Unknown')}")
                
                tool_name = step.get("tool_name")
                parameters = step.get("parameters", {})
                
                if not tool_name:
                    self.logger.warning(f"Step {i+1} has no tool name, skipping")
                    continue
                
                if not self.tool_registry.has_tool(tool_name):
                    self.logger.warning(f"Tool '{tool_name}' not found, skipping step {i+1}")
                    continue
                
                # æ‰§è¡Œå·¥å…·
                result = self.tool_registry.execute_tool(tool_name, **parameters)
                results.append(result)
                
                self.logger.info(f"Step {i+1} completed successfully")
                
            except Exception as e:
                self.logger.error(f"Step {i+1} failed: {str(e)}")
                results.append(f"Step {i+1} failed: {str(e)}")
        
        # æ±‡æ€»ç»“æœ
        if results:
            final_result = results[-1]  # é€šå¸¸æœ€åä¸€æ­¥çš„ç»“æœæ˜¯æœ€ç»ˆç»“æœ
            return f"Processing completed. Result: {final_result}"
        else:
            return "Processing completed, but no results were generated."
    
    def register_tool(self, func, name: str = None, description: str = None):
        """æ³¨å†Œæ–°çš„å·¥å…·å‡½æ•°
        
        Args:
            func: å·¥å…·å‡½æ•°
            name: å·¥å…·åç§°
            description: å·¥å…·æè¿°
        """
        return self.tool_registry.register(func, name=name, description=description)
    
    def list_tools(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨å·¥å…·"""
        return self.tool_registry.list_tools()
    
    def get_tool_info(self, tool_name: str) -> Dict:
        """è·å–å·¥å…·ä¿¡æ¯"""
        return self.tool_registry.get_tool_info(tool_name)
    
    async def analyze_video_content(
        self, 
        video_path: str, 
        target_description: str
    ) -> List[DetectionRegion]:
        """åˆ†æè§†é¢‘å†…å®¹ï¼Œè¯†åˆ«ç›®æ ‡å¯¹è±¡
        
        Args:
            video_path: è§†é¢‘è·¯å¾„
            target_description: ç›®æ ‡æè¿°
            
        Returns:
            æ£€æµ‹åŒºåŸŸåˆ—è¡¨
        """
        try:
            # æå–å…³é”®å¸§
            if not self.tool_registry.has_tool("extract_video_frames"):
                raise VideoAgentException("extract_video_frames tool not available")
            
            frames_info_str = self.tool_registry.execute_tool(
                "extract_video_frames", 
                video_path=video_path,
                sample_rate=15,  # é™ä½é‡‡æ ·ç‡ï¼Œæ¯15å¸§æå–ä¸€å¸§
                max_frames=30,   # å¢åŠ å…³é”®å¸§æ•°é‡ï¼Œæé«˜è¿½è¸ªç²¾åº¦
                use_motion_detection=True,
                single_best_frame=False
            )
            
            import json
            frames_data = json.loads(frames_info_str)
            frames = [
                FrameInfo(
                    frame_id=f["frame_id"],
                    timestamp=f["timestamp"],
                    image_path=f["image_path"],
                    width=f.get("width", 1920),
                    height=f.get("height", 1080)
                )
                for f in frames_data["frames"]
            ]
            
            # LLMåˆ†æ
            regions = await self.llm_client.analyze_video_frames(frames, target_description)
            
            return regions
            
        except Exception as e:
            raise VideoAgentException(f"Video content analysis failed: {str(e)}") from e
    
    async def enhance_annotation_with_tracking(
        self, 
        video_path: str, 
        seed_regions: List[DetectionRegion],
        target_description: str = "æ‰‹æœº"
    ) -> List[DetectionRegion]:
        """ä½¿ç”¨ç§å­æ ‡æ³¨å¢å¼ºLLMè¿½è¸ªåˆ†æ
        
        Args:
            video_path: è§†é¢‘è·¯å¾„
            seed_regions: ç”¨æˆ·æ‰‹åŠ¨æ ‡æ³¨çš„ç§å­åŒºåŸŸ
            target_description: ç›®æ ‡æè¿°
            
        Returns:
            å¢å¼ºåçš„å®Œæ•´è¿½è¸ªåŒºåŸŸåˆ—è¡¨
        """
        try:
            print(f"ğŸŒ± å¼€å§‹ç§å­å¢å¼ºè¿½è¸ªï¼Œç§å­åŒºåŸŸæ•°é‡: {len(seed_regions)}")
            for i, seed in enumerate(seed_regions):
                print(f"   ç§å­{i+1}: å¸§{seed.frame_id}, ä½ç½®({seed.bbox[0]},{seed.bbox[1]}), å¤§å°{seed.bbox[2]}x{seed.bbox[3]}")
            
            # è·å–è§†é¢‘ä¿¡æ¯ç”¨äºåæ ‡éªŒè¯
            if self.tool_registry.has_tool("get_video_info"):
                info_str = self.tool_registry.execute_tool("get_video_info", video_path=video_path)
                video_info = json.loads(info_str)
                print(f"ğŸ“ è§†é¢‘åˆ†è¾¨ç‡: {video_info.get('width', 'unknown')}x{video_info.get('height', 'unknown')}")
            else:
                print("âš ï¸  æ— æ³•è·å–è§†é¢‘ä¿¡æ¯è¿›è¡Œåæ ‡éªŒè¯")
            
            # ä½¿ç”¨å¤šå¸§LLMåˆ†æè¿›è¡Œè¿½è¸ª
            llm_regions = await self.analyze_video_content(video_path, target_description)
            
            # åˆå¹¶ç§å­æ ‡æ³¨å’ŒLLMè¿½è¸ªç»“æœ
            enhanced_regions = []
            
            # ä¿ç•™ç§å­æ ‡æ³¨ï¼ˆç”¨æˆ·æ ‡æ³¨ä¼˜å…ˆçº§æœ€é«˜ï¼‰
            for seed_region in seed_regions:
                enhanced_regions.append(seed_region)
            
            # æ·»åŠ LLMå‘ç°çš„å…¶ä»–å¸§ä¸­çš„ç›®æ ‡ä½ç½®
            seed_frame_ids = {region.frame_id for region in seed_regions}
            llm_added_count = 0
            for llm_region in llm_regions:
                if llm_region.frame_id not in seed_frame_ids:
                    # ä¸ºLLMæ£€æµ‹çš„åŒºåŸŸæ·»åŠ è¿½è¸ªæ ‡è¯†
                    llm_region.description = f"{llm_region.description} (LLMè¿½è¸ª)"
                    enhanced_regions.append(llm_region)
                    llm_added_count += 1
            
            print(f"ğŸ“Š åˆå¹¶ç»“æœï¼š{len(seed_regions)}ä¸ªç§å­æ ‡æ³¨ + {llm_added_count}ä¸ªLLMè¿½è¸ª = {len(enhanced_regions)}ä¸ªæ€»åŒºåŸŸ")
            
            # æ˜¾ç¤ºLLMè¿½è¸ªçš„åæ ‡ä¿¡æ¯ç”¨äºè°ƒè¯•
            if llm_added_count > 0:
                print("ğŸ” LLMè¿½è¸ªåæ ‡è¯¦æƒ…:")
                for region in enhanced_regions:
                    if "(LLMè¿½è¸ª)" in region.description:
                        print(f"   å¸§{region.frame_id}: ä½ç½®({region.bbox[0]},{region.bbox[1]}), å¤§å°{region.bbox[2]}x{region.bbox[3]}")
            
            return enhanced_regions
            
        except Exception as e:
            # å¦‚æœLLMè¿½è¸ªå¤±è´¥ï¼Œè‡³å°‘è¿”å›ç§å­æ ‡æ³¨
            self.logger.warning(f"LLM tracking enhancement failed: {str(e)}, falling back to seed regions only")
            return seed_regions

    async def create_manual_annotation_workflow(
        self, 
        video_path: str, 
        target_description: str = "æ‰‹æœº"
    ) -> str:
        """åˆ›å»ºæ‰‹åŠ¨æ ‡æ³¨å·¥ä½œæµ
        
        Args:
            video_path: è§†é¢‘è·¯å¾„
            target_description: ç›®æ ‡æè¿°
            
        Returns:
            å·¥ä½œæµä¿¡æ¯å’Œè¯´æ˜
        """
        try:
            if not self.tool_registry.has_tool("create_annotation_workflow"):
                raise VideoAgentException("create_annotation_workflow tool not available")
            
            workflow_result = self.tool_registry.execute_tool(
                "create_annotation_workflow",
                video_path=video_path,
                target_description=target_description
            )
            
            return workflow_result
            
        except Exception as e:
            raise VideoAgentException(f"Manual annotation workflow creation failed: {str(e)}") from e